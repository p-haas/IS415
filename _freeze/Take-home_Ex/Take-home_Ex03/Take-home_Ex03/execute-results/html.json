{
  "hash": "7883ba0c39686cfafc5eadfcb8f5288b",
  "result": {
    "markdown": "---\ntitle: \"Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods\"\nsubtitle: \"Take-home Exercise 3\"\n\nauthor: \"Pierre HAAS\"\n\ndate: \"March 07, 2023\"\ndate-modified: \"2023-03-26\"\n\nexecute:\n  eval: true\n  echo: true\n  warning: false\neditor: visual\n\nnumber-sections: true\n---\n\n\n# Getting Started\n\nIn this Take-home Exercise 3, we will try using geographically weighted methods to predict the resale price of HDB public housing in Singapore. You will find in the next to sections a brief description of the data sets used and where to retrieve them as well as the list of all the libraries needed for this project and a description of their specific usage.\n\n## Installing and Loading Packages\n\nFor the purpose our this project, we have selected a list of libraries that will allow to perform all the necessary data cleaning, handling and analysis.\n\nThe following list shows the libraries that will be used and their purpose for this assignment:\n\n-   pacman\n\n-   tidyverse\n\n-   janitor\n\n-   sf\n\n-   spdep\n\n-   tmap\n\n-   corrplot\n\n-   olsrr\n\n-   gtsummary\n\n-   knitr\n\n-   httr\n\n-   onemapsapi\n\n-   xml2\n\n-   rvest\n\n-   stringr\n\n-   ggmap\n\n-   ggpubr\n\n-   GWmodel\n\n-   SpatialML\n\n-   Metrics\n\n-   rsample\n\nTo install and load the packages, we use the p_load() function of the pacman package. It automatically checks if packages are installed, installs them if they are not installed, and loads the packages into the R environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep,\n               GWmodel, tmap, tidyverse, gtsummary,\n               ranger, SpatialML, rsample, Metrics,\n               janitor, stargazer, lmtest, robustbase)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(knitr, httr, onemapsgapi, xml2, rvest,\n               stringr, ggmap)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(digits = 15)\n```\n:::\n\n\n## The Data\n\nFor the purpose of this assignment, extensive amount of data was extracted from the web. You will find below a table that directs you to the webpage on which you can retrieve the data sets.\n\n# Retrieving and Importing the Geospatial Data\n\nIn this first section that addresses the data import, we will be going through the necessary work to load the geospatial data correctly into our R environment.\n\nNote that in this section, we will be load data previously retrieved from the web, but also using some APIs to collect necessary variables that will play an important role in our regression models.\n\n## Master Plan 2019 with sub-zones\n\n::: panel-tabset\n### Importing the data\n\nThe first geospatial data set that we are importing is the 2019 Master Plan with sub-zones. Since it is a shp file, we use the st_read() function of the sf package to properly import the data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmpsz.sf = st_read(dsn = \"data/geospatial/mpsz2019\",\n                  layer = \"MPSZ-2019\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `MPSZ-2019' from data source \n  `C:\\p-haas\\IS415\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\mpsz2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.605700705134 ymin: 1.15869870063517 xmax: 104.088483065163 ymax: 1.47077483208461\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\nThe import was successful, however, before moving on I would like to check if all geometries are valid, and also if the projection code is correectly encoded.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nany(st_is_valid(mpsz.sf) == FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nIt seems like we have invalid geometries. Now, let's check the CRS code of the data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nst_crs(mpsz.sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n```\n:::\n:::\n\n\nIt looks like the EPSG and coordinate system does not correspond to the Singaporean SVY21. So, we will change that. We pipe the st_transform() and st_make_valid() functions to solve the two issues we had just pointed out.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmpsz.sf = mpsz.sf %>%\n  st_make_valid() %>%\n  st_transform(3414)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nany(st_is_valid(mpsz.sf) == FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nst_crs(mpsz.sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n```\n:::\n:::\n\n\nThe two issues seem to be solved. Note that I show you how to proceed when importing geospatial data here but will not do so in such an extensive manner later. My goal here is to show you how to replicate my way of proceeding when handling the data for the first time. To make the reading easier, I have cut out all my exploration of this webpage and left only the essential and necessary code.\n\n### Visualizing the data\n\nUsing the qtm() function of the tmap package, we can make a quick visualization of the geometry stored in the sf data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(mpsz.sf)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n\n## MRT Train stations\n\nImporting MRT Exits into an sf data frame.\n\n::: panel-tabset\n### Importing the data\n\nAs explained just before, I will be sticking with the necessary code only from now on. Using the following code chunk, we import the MRT Train Stations into an sf data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmrt_exits.sf = st_read(dsn = \"data/geospatial/TrainStationExit/TrainStationExit\",\n                       layer = \"Train_Station_Exit_Layer\") %>%\n  st_transform(crs=3414)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `Train_Station_Exit_Layer' from data source \n  `C:\\p-haas\\IS415\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\TrainStationExit\\TrainStationExit' \n  using driver `ESRI Shapefile'\nSimple feature collection with 562 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 6134.08550000004 ymin: 27499.6967999991 xmax: 45356.3619999997 ymax: 47865.9227000009\nProjected CRS: SVY21\n```\n:::\n:::\n\n\n### Visualizing the data\n\nUsing the tmap package, we can conveniently plot the MRT Exits on the Singaporean map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(mrt_exits.sf)+\n  tm_dots(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n:::\n\n## Bus Stop Locations\n\nImporting Bus Stops into an sf data frame.\n\n::: panel-tabset\n### Importing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbus_stops.sf = st_read(dsn = \"data/geospatial/BusStopLocation/BusStop_Feb2023\",\n                       layer = \"BusStop\") %>%\n  st_transform(3414)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `BusStop' from data source \n  `C:\\p-haas\\IS415\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\BusStopLocation\\BusStop_Feb2023' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.12161372974 ymin: 26482.1007183008 xmax: 48284.5630137296 ymax: 52983.8165183011\nProjected CRS: SVY21\n```\n:::\n:::\n\n\n### Visualizing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(bus_stops.sf)+\n  tm_dots(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n:::\n\n## Supermarket data\n\nImporting Supermarket Locations into an sf data frame.\n\n::: panel-tabset\n### Importing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsupermarkets.sf = st_read(\"data/geospatial/supermarkets/supermarkets-kml.kml\") %>%\n  st_transform(3414)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `SUPERMARKETS' from data source \n  `C:\\p-haas\\IS415\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\supermarkets\\supermarkets-kml.kml' \n  using driver `KML'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.625764663231 ymin: 1.2471504063107 xmax: 104.003578458884 ymax: 1.46152554782754\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\n### Visualizing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(supermarkets.sf)+\n  tm_dots(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n:::\n\n## Retrieving the independent variables using the OneMap API\n\nWe will be using the One Map Singapore API to retrieve some of the independent variables that we will be using later on in our regression model.\n\nWe will be taking a few preliminary steps before extracting the variables. You will find everything you need to replicate my work in the following sections.\n\n### Retrieving the API token using the *onemapsgapi* package\n\nThe first step to getting the API key is to create an account on the One Map website (click [here](https://www.onemap.gov.sg/docs/#register-free-account) to access the registration tutorial).\n\nNow that you are registered, we may retrieve the API key using the *onemapsgapi* package and its get_token() function. By simply entering your registration email and password, you will get a valid API key for a three-day period.\n\nNote that if you want to learn more about the One Map API, you should definitely check their [website](https://www.onemap.gov.sg/docs/) and their [web app](https://app.swaggerhub.com/apis/onemap-sg/new-onemap-api/1.0.4) that allows to test the API's services.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntoken_api = get_token(email = \"xxx@xxx.xxx\", \n                      password = \"...\")\n```\n:::\n\n\n### Using the API to retrieve the variables available on OneMap\n\nThe first step to retrieving our independent variables is to look at the available data provided by One Map. We do so using the httr package that allows us to make HTML queries. Using the GET() function, we retrieve every theme info of the OneMap API.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl = \"https://developers.onemap.sg/privateapi/themesvc/getAllThemesInfo\"\n\nquery <- list(\"token\" = token_api)\nresult <- GET(url, query = query)\n```\n:::\n\n\nUsing the content() function, we may look at the information retrieved, however, you should be made aware that the result from our GET() command is quite messy. So, you will see in the next section how we extract the theme names and store them into a list.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontent(result)\n```\n:::\n\n\n### Creating the variable list\n\nAs explained, the information retrieved is quite messy. So, we will be storing in a list the essential information that we will use later on.\n\nUsing a for loop, I store the theme specific information into a list called themes_list.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthemes_list = list()\n\nfor (i in 1:length(content(result)$Theme_Names)){\n  themes_list = append(themes_list, content(result)$Theme_Names[[i]])\n}\n```\n:::\n\n\nTo take a look at the information stored into our list, you may use the next code chunk. However, since the list is quite long, I won't print the output/information here and will directly give you a list you the variables I have extracted.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthemes_list\n```\n:::\n\n\nIn the next code chunk, you may see the variables that I carefully selected. They give information about: Eldercare Services, Hawker Centres, Food Courts, Parks in Singapore, Kindergartens, and Childcare Centres.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nind_variables = c(\"eldercare\", \"hawkercentre\", \"hawkercentre_new\", \"healthier_hawker_centres\", \"maxwell_fnb_map\", \"healthiercaterers\", \"relaxsg\", \"nationalparks\", \"kindergartens\", \"childcare\")\n```\n:::\n\n\nI have also picked-up some other interesting variables that may be included later in my regression model to improve the quality of the future model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextra_variables = c(\"lta_cycling_paths\", \"disability\", \"hsgb_fcc\", \"sportsg_sport_facilities\", \"ssc_sports_facilities\", \"wastedisposalsite\", \"drainageconstruction\", \"cpe_pei_premises\", \"sewerageconstruction\", \"danger_areas\", \"aquaticsg\", \"moh_isp_clinics\", \"heritagetrees\", \"nparks_activity_area\",  \"exercisefacilities\", \"mha_uav_2015\", \"playsg\", \"underconstruction_facilities\", \"preschools_location\", \"hdbcyclingunderconstruction\",  \"boundary_5km\",  \"hdbluppropunderconstruction\", \"parkingstandardszone\", \"libraries\", \"cyclingpath\", \"dengue_cluster\", \"greenbuilding\", \"nparks_uc_parks\", )\n```\n:::\n\n\nYou won't see these additional variables in my model due to the computing power of my computer. However, I strongly recommend to try an include these potential independent variables to improve the model.\n\n### Retrieving the available variables with the OneMap API\n\nUsing the code chunk below, you can retrieve the location name and its coordinates based on the previously created list of variables. We store this information into a data frame to make our use of this data easier\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf = data.frame()\n\nurl = \"https://developers.onemap.sg/privateapi/themesvc/retrieveTheme\"\n\nfor (x in ind_variables){\n  \n  query <- list(\"queryName\" = x, \"token\" = token_api)\n  \n  result <- GET(url, query = query)\n  \n  print(\"Start\")\n  print(x)\n  \n  for (i in 2:length(content(result)$SrchResults)){\n    new_row = c(content(result)$SrchResults[[i]]$NAME,\n                str_split_fixed(content(result)$SrchResults[[i]]$LatLng, \",\", 2)[1],\n                str_split_fixed(content(result)$SrchResults[[i]]$LatLng, \",\", 2)[2],\n                content(result)$SrchResults[[1]]$Theme_Name)\n    \n    df = rbind(df, new_row)\n  }\n\n}\n\ncolnames(df)<-c(\"location_name\", \"lat\", \"lon\", \"variable_name\")\n```\n:::\n\n\nNote that retrieving the data takes a few minutes, so I took care of exporting the data frame into a csv file to avoid running the previous code chunk multiple times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(df, \"data/geospatial/retrieved_variables.csv\")\n```\n:::\n\n\nWe now have part of our independent variables stored into a csv file that we will import back into our R environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretrieved_variables = read_csv(\"data/geospatial/retrieved_variables.csv\", )\n```\n:::\n\n\nIf we look back to the variables we chose to retrieve using the One Map API, we had sub-categories to our independent variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(retrieved_variables$variable_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"eldercare\"      \"hawker_centres\" \"parks\"          \"kindergartens\" \n[5] \"child_care\"    \n```\n:::\n:::\n\n\nFor instance, we have four sub-categories for hawker centres and food courts. We shall simplify our work by renaming these sub-categories under one name only. Using the next code chunk, we may do so.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Eldercare Services\", \n                                                \"eldercare\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"^Hawker Centres$\", \n                                                \"hawker_centres\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Hawker Centres_New\", \n                                                \"hawker_centres\")\n\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Healthier Hawker Centres\", \n                                                \"hawker_centres\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Maxwell Chambers F&B map\", \n                                                \"hawker_centres\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Healthier Caterers\", \n                                                \"hawker_centres\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Parks@SG\", \n                                                \"parks\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Parks\", \n                                                \"parks\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Kindergartens\", \n                                                \"kindergartens\")\n\nretrieved_variables$variable_name = str_replace(retrieved_variables$variable_name, \n                                                \"Child Care Services\", \n                                                \"child_care\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(retrieved_variables$variable_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"eldercare\"      \"hawker_centres\" \"parks\"          \"kindergartens\" \n[5] \"child_care\"    \n```\n:::\n:::\n\n\nWe shall now proceed to creating sf objects from the extracted coordinates.\n\n### Transforming the data frame to sf data frame\n\nUsing the st_as_sf() function from the *sf* package, we can transform our set of coordinates into sf point objects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretrieved_variables.sf = st_as_sf(retrieved_variables,\n                                  coords = c(\"lon\", \"lat\"),\n                                  crs = 4326) %>%\n  st_transform(3414)\n```\n:::\n\n\nWe shall check if our data points have been correctly transformed by plotting the points on the Singapore map using the *tmap* package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(retrieved_variables.sf)+\n  tm_dots()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n# Retrieving and Importing the Aspatial Data\n\n## Resale Price of HDB flats\n\nAfter retrieving the resale HDB prices from the data.gov.sg website, I moved the folder into my data folder, it contains all the data sets necessary for our analysis, and more precisely stored it into the aspatial folder.\n\nThe downloaded data is stored in a folder called resale-flat-prices, itself containing multiple files. To choose the right file, we can use the base r function list.files() to return a list of the file's names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath = \"data/aspatial/resale-flat-prices\"\nfiles = list.files(path)\nfiles\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"metadata-resale-flat-prices.txt\"                                            \n[2] \"resale-flat-prices-based-on-approval-date-1990-1999.csv\"                    \n[3] \"resale-flat-prices-based-on-approval-date-2000-feb-2012.csv\"                \n[4] \"resale-flat-prices-based-on-registration-date-from-jan-2015-to-dec-2016.csv\"\n[5] \"resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\"    \n[6] \"resale-flat-prices-based-on-registration-date-from-mar-2012-to-dec-2014.csv\"\n```\n:::\n:::\n\n\nLooking at the above list, it seems clear that we should use file n°5 as it contains the data from 2017 and later. It gives us the intuition that we may need to treat the data and take a subset of data rows within the analysis period (2021 to 2023). We will import the data using the read_csv() function from the readr package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresale_price = read_csv(file = paste(path, files[5], sep = \"/\"))\n```\n:::\n\n\nWe should take a quick look at the fields contained in the resale_price data frame. We do so using the glimpse() function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(resale_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 148,096\nColumns: 11\n$ month               <chr> \"2017-01\", \"2017-01\", \"2017-01\", \"2017-01\", \"2017-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"2 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"406\", \"108\", \"602\", \"465\", \"601\", \"150\", \"447\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 4\", \"ANG MO K…\n$ storey_range        <chr> \"10 TO 12\", \"01 TO 03\", \"01 TO 03\", \"04 TO 06\", \"0…\n$ floor_area_sqm      <dbl> 44, 67, 67, 68, 67, 68, 68, 67, 68, 67, 68, 67, 67…\n$ flat_model          <chr> \"Improved\", \"New Generation\", \"New Generation\", \"N…\n$ lease_commence_date <dbl> 1979, 1978, 1980, 1980, 1980, 1981, 1979, 1976, 19…\n$ remaining_lease     <chr> \"61 years 04 months\", \"60 years 07 months\", \"62 ye…\n$ resale_price        <dbl> 232000, 250000, 262000, 265000, 265000, 275000, 28…\n```\n:::\n:::\n\n\nThe available fields are as follows:\n\n-   month: it indicates the month of transaction\n-   town: it indicates the district\n-   flat_type: it indicates the number of rooms in the flat\n-   block: it indicates the block number of the HDB flat\n-   street_name: it indicates the street number and name\n-   storey_range: it indicates the floor number of the flat\n-   floor_area_sqm: it indicates the floor area of the flat in square meter\n-   flat_model: it indicates the HDB flat model\n-   lease_commence_date: it indicates the starting year date of the lease (in Singapore, HDB flats are 99-year leaseholds)\n-   remaining_lease: it indicates the remaining years and months on the 99-year leasehold\n-   resale_price: it indicates the resale price of a given flat in SGD (Singapore dollars)\n\nNow, we will use the head() function to look at the available data in each field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(resale_price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 11\n  month   town     flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n  <chr>   <chr>    <chr>   <chr> <chr>   <chr>     <dbl> <chr>     <dbl> <chr>  \n1 2017-01 ANG MO … 2 ROOM  406   ANG MO… 10 TO …      44 Improv…    1979 61 yea…\n2 2017-01 ANG MO … 3 ROOM  108   ANG MO… 01 TO …      67 New Ge…    1978 60 yea…\n3 2017-01 ANG MO … 3 ROOM  602   ANG MO… 01 TO …      67 New Ge…    1980 62 yea…\n4 2017-01 ANG MO … 3 ROOM  465   ANG MO… 04 TO …      68 New Ge…    1980 62 yea…\n5 2017-01 ANG MO … 3 ROOM  601   ANG MO… 01 TO …      67 New Ge…    1980 62 yea…\n6 2017-01 ANG MO … 3 ROOM  150   ANG MO… 01 TO …      68 New Ge…    1981 63 yea…\n# … with 1 more variable: resale_price <dbl>, and abbreviated variable names\n#   ¹​flat_type, ²​street_name, ³​storey_range, ⁴​floor_area_sqm, ⁵​flat_model,\n#   ⁶​lease_commence_date, ⁷​remaining_lease\n```\n:::\n:::\n\n\n### Selecting trasactions of 3 Room apartments from 2021 onwards\n\nMy previously mentioned intuition is confirmed. The month variable takes data starting in January 2017 and, through quick data manipulation, we will have to restrain the data frames to the 2021-2022 analysis period and 2023 data testing period. In addition, it looks like the town field in unnecessary and may be dropped. We only need the block and steet_name fields to geocode the addresses and create sf geometry.\n\nHere we pipe the select() function to remove the town variable, filter and grepl functions to create a subset of the data by only selecting transactions that took place in 2021 to 2023, and finally pipe once again the filter function to select only three room HDB flats.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms = resale_price %>%\n  select(-2) %>%\n  filter(grepl(\"202[123]\", month)) %>%\n  filter(flat_type == \"3 ROOM\")\n```\n:::\n\n\n### Transforming the storey_range column to dummy variables\n\nSince we would like to include the storey_range variable in our analysis and the column only takes categorical data, we shall create dummy variables to indicate the storey range of each HDB flat.\n\nThe first step is to look at what are the unique values in the column. Using the unique() function, we retrieve in the form of a list the unique categorical values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(rp_3rooms$storey_range)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"04 TO 06\" \"01 TO 03\" \"07 TO 09\" \"10 TO 12\" \"13 TO 15\" \"16 TO 18\"\n [7] \"19 TO 21\" \"25 TO 27\" \"22 TO 24\" \"37 TO 39\" \"31 TO 33\" \"34 TO 36\"\n[13] \"40 TO 42\" \"46 TO 48\" \"28 TO 30\" \"43 TO 45\"\n```\n:::\n:::\n\n\nNow, using a for loop and the ifelse() function, we will create a new column for each unique categorical variable contained in the storey_range field and assign a 1 if the particular HDB flat belongs to the specific storey range.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (i in unique(rp_3rooms$storey_range)){\n  rp_3rooms[i] = ifelse(rp_3rooms$storey_range == i, 1, 0)\n}\n```\n:::\n\n\n### Transforming the flat_model column to dummy variables\n\nWe repeat the same process with the flat_model variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(rp_3rooms$flat_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"New Generation\"    \"Improved\"          \"Model A\"          \n[4] \"Simplified\"        \"Standard\"          \"Premium Apartment\"\n[7] \"DBSS\"              \"Terrace\"          \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (i in unique(rp_3rooms$flat_model)){\n  rp_3rooms[i] = ifelse(rp_3rooms$flat_model == i, 1, 0)\n}\n```\n:::\n\n\n### Transforming the remaining_lease to a numerical variable\n\nIf you remember previously when we took a look at the different data fields available in our data frame, you could notice that the remaining_lease variable stored character data, however, we would like it to be a numerical data field.\n\nTo transform our column into a numerical field, we use a for loop with if/else statements. This will allow us to extract the number of years and months remaining on the lease and create a variable that stores the years remaining before expiration of the lease.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlease_remaining = list()\n\nfor (i in 1:nrow(rp_3rooms)){\n  \n  lease = str_extract_all(rp_3rooms$remaining_lease, \"[0-9]+\")[[i]]\n  \n  year = as.numeric(lease[1])\n  \n  if (length(lease) < 2){\n    \n    lease_remaining = append(lease_remaining, year)\n  \n    } else {\n      \n    month = as.numeric(lease[2])\n    \n    lease_remaining = append(lease_remaining, round(year+month/12, 2))\n  \n    }\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms$remaining_lease = as.numeric(lease_remaining)\n```\n:::\n\n\n### Geocoding the address\n\nThe first step to geocoding the address - retrieving the latitude and longitude based in the address - is to create a new column that stores the cleaned full address. Consequently, we create a new field called cleaned_address that combines both the block and street_name fields. This will allow us to retrieve the geocode of the HDB flats in our query.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms[\"cleaned_address\"] = paste(rp_3rooms$block, rp_3rooms$street_name, sep = \" \")\n```\n:::\n\n\nNow that we have a column that stores the cleaned addresses, we can move on to the geocoding. By using the httr package and One Map API, we will create GET requests that retrieve the full address of the HDB flat, its longitude and latitude. We will store all this data into three lists to later create three additional columns in our data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl = \"https://developers.onemap.sg/commonapi/search\"\n\nfull_address = list()\nlatitude = list()\nlongitude = list()\n\nfor (address in rp_3rooms$cleaned_address){\n  query <- list(\"searchVal\" = address,\n                \"returnGeom\" = \"Y\", \"getAddrDetails\" = \"Y\")\n  res <- GET(url, query = query)\n  \n  full_address = append(full_address, content(res)$results[[1]]$ADDRESS)\n  latitude = append(latitude, content(res)$results[[1]]$LATITUDE)\n  longitude = append(longitude, content(res)$results[[1]]$LONGITUDE)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms$full_address = full_address\nrp_3rooms$lat = latitude\nrp_3rooms$lon = longitude\n```\n:::\n\n\nBefore exporting the data frame to a csv file (to avoid repeating this lengthy step), we shall use the apply function to transform our three newly created columns to the right type (character / numerical type).\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(digits=15)\n\nrp_3rooms$full_address = apply(rp_3rooms[, 28], 2, as.character)\nrp_3rooms$lat = apply(rp_3rooms[, 29], 2, as.numeric)\nrp_3rooms$lon = apply(rp_3rooms[, 30], 2, as.numeric)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(rp_3rooms, \"data/aspatial/geocoded_resale_price.csv\", row.names = FALSE)\n```\n:::\n\n\nWe import the geocoded data back into the R environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms = read_csv(\"data/aspatial/geocoded_resale_price.csv\")\n```\n:::\n\n\n### Dropping the irrelevant variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(rp_3rooms)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 38\n  month   flat_t…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷ resal…⁸\n  <chr>   <chr>    <chr> <chr>   <chr>     <dbl> <chr>     <dbl>   <dbl>   <dbl>\n1 2021-01 3 ROOM   331   ANG MO… 04 TO …      68 New Ge…    1981    59    260000\n2 2021-01 3 ROOM   534   ANG MO… 04 TO …      68 New Ge…    1980    58.2  265000\n3 2021-01 3 ROOM   561   ANG MO… 01 TO …      68 New Ge…    1980    58.1  265000\n4 2021-01 3 ROOM   170   ANG MO… 07 TO …      60 Improv…    1986    64.2  268000\n5 2021-01 3 ROOM   463   ANG MO… 04 TO …      68 New Ge…    1980    58.2  268000\n6 2021-01 3 ROOM   542   ANG MO… 04 TO …      68 New Ge…    1981    59.1  270000\n# … with 28 more variables: `04 TO 06` <dbl>, `01 TO 03` <dbl>,\n#   `07 TO 09` <dbl>, `10 TO 12` <dbl>, `13 TO 15` <dbl>, `16 TO 18` <dbl>,\n#   `19 TO 21` <dbl>, `25 TO 27` <dbl>, `22 TO 24` <dbl>, `37 TO 39` <dbl>,\n#   `31 TO 33` <dbl>, `34 TO 36` <dbl>, `40 TO 42` <dbl>, `46 TO 48` <dbl>,\n#   `28 TO 30` <dbl>, `43 TO 45` <dbl>, cleaned_address <chr>,\n#   full_address <chr>, lat <dbl>, lon <dbl>, `New Generation` <dbl>,\n#   Improved <dbl>, `Model A` <dbl>, Simplified <dbl>, Standard <dbl>, …\n```\n:::\n:::\n\n\nWe will drop the following irrelevant fields.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.cleaned = rp_3rooms %>%\n  select(-c(\"flat_type\", \"block\", \"street_name\", \"storey_range\", \"flat_model\", \"cleaned_address\", \"full_address\"))\n```\n:::\n\n\n### Creating the sf geometry\n\nUsing the tibble data frame and lon/lat fields, we create a sf data frame and visualize the data with the tmap package.\n\n::: panel-tabset\n#### Creating the sf data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf = st_as_sf(rp_3rooms.cleaned,\n                        coords = c(\"lon\", \"lat\"),\n                        crs = 4326) %>%\n  st_transform(3414)\n```\n:::\n\n\n#### Visualizing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(rp_3rooms.sf)+\n  tm_dots()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n:::\n\n\n:::\n\n## Primary School data\n\nAfter thoroughly looking on the web, I was not able to find a list of primary schools of Singapore to download. So, to improve the reproducibility of my work, I scrapped the [sgschooling](https://sgschooling.com/school/) website to retrieve what seemed to me like an up-to-date list of primary schools.\n\n### Scrapping Primary Schools online with *rvest* package\n\nThe first step is to retrieve the names of the primary schools. Looking at the code chunk below, I used the *httr*, *xml2*, and *rvest* packages to create a GET request, read the HTML code of the website, and extract the names of the schools to store them into a list.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl = \"https://sgschooling.com/school/\"\n\nres = GET(url)\n\nwiki_read <- xml2::read_html(res, encoding = \"UTF-8\")\n\ntestt = wiki_read %>%\n  html_elements(\"a\")\n\ntestt1 = testt[grepl(\"school/\", testt)]\n\npattern <- \">(.*)<\"\nresult <- regmatches(testt1, regexec(pattern, testt1))\n\nschools = list()\n\nfor (i in 1:length(result)){\n  new_row = result[[i]][2]\n  schools = append(schools, new_row)\n}\n```\n:::\n\n\n### Using the OneMap API to retrieve the schools' coordinates\n\nI then used this list and the One Map API to geocode these schools and retrieve their address as well as their longitude and latitude, and then stored all of it into a data frame.\n\nNote that in my code I include an if/else statement in the case where we do not get a perfect match and are not able to retrieve information with the API.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc = data.frame()\n\nurl = \"https://developers.onemap.sg/commonapi/search\"\n\nfor (i in 1:length(schools)){\n  \n  query <- list(\"searchVal\" = schools[[i]],\n                \"returnGeom\" = \"Y\", \n                \"getAddrDetails\" = \"Y\")\n  result <- GET(url, query = query)\n  \n  if (length(content(result)$results) == 0){\n    new_row = c(schools[[i]], \n              NA,\n              NA,\n              NA)\n    primary_sc = rbind(primary_sc, new_row)\n    \n  } else{\n    new_row = c(schools[[i]], \n                content(result)$results[[1]]$ADDRESS,\n                content(result)$results[[1]]$LATITUDE,\n                content(result)$results[[1]]$LONGITUDE)\n    \n    primary_sc = rbind(primary_sc, new_row)\n    \n  }\n\n}\n\ncolnames(primary_sc) = c(\"location_name\", \"full_address\", \"lat\", \"lon\")\n```\n:::\n\n\n### Checking for missing information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(primary_sc$full_address))\n```\n:::\n\n\nIt seems like we have missing data for 9 primary schools. It is probably because the name of the school is not recognized by the API, so we will try to clean them to get their information into our data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc %>%\n  filter(is.na(primary_sc$full_address) == TRUE) %>%\n  select(1)\n```\n:::\n\n\nBy checking on the web, it seems like the \"Juying Primary School\" has merged with the \"Pioneer Primary School\", so we may drop the \"Juying Primary School\" from the data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc1 = primary_sc %>%\n  filter(!grepl(\"Juying Primary School\", location_name))\n```\n:::\n\n\nNow, regarding the remaining schools, after performing a tests, it seems like I am not able to retrieve the information using the API so we will be filling the values with, first, the Google Maps API and then, if there are still some empty information, I will be filling the values manually by looking online.\n\nYou may want to check the next two code chunks I have used to try and retrieve the missing information using the OneMap API.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc1$location_name = str_replace(primary_sc1$location_name, \n                                        \"St. \", \"\")\n\n# I have also tried replacing the string with: \"Saint\" and \"St\" but I am not able to make the API retrieve the data\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nurl = \"https://developers.onemap.sg/commonapi/search\"\n\nfor (i in 1:nrow(primary_sc1)){\n  \n  if (is.na(primary_sc1[i, 2])){\n    query <- list(\"searchVal\" = primary_sc1[i, 1],\n                  \"returnGeom\" = \"Y\", \n                  \"getAddrDetails\" = \"Y\")\n    result <- GET(url, query = query)\n    \n    if (length(content(result)$results) == 0){\n      next\n      \n      } else{\n        primary_sc1[i, 2] = content(result)$results[[1]]$ADDRESS\n        primary_sc1[i, 3] = content(result)$results[[1]]$LATITUDE\n        primary_sc1[i, 4] = content(result)$results[[1]]$LONGITUDE\n    \n  }} else{ next\n  \n  }\n}\n```\n:::\n\n\nThese are the schools with the missing information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc1 %>%\n  filter(is.na(primary_sc1$full_address) == TRUE) %>%\n  select(1)\n```\n:::\n\n\nUsing the Google Maps API and its library *ggmap*, we will loop through the schools with missing coordinates. Since all these schools are located consecutively in the data frame, I use the following structure to create the list of schools.\n\nWhile looping through these schools, we use the geocode() function of *ggmap* to retrieve the latitude and longitude based on the school name and assign these values in the corresponding missing cells of the primary_sc1 data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregister_google(key = \"xxx\")\n\nmissing_sc = primary_sc1[grep(\"St. Andrew’s Junior School\", primary_sc1$location_name):grep(\"St. Stephen’s School\", primary_sc1$location_name), 1]\n\nfor (i in missing_sc){\n  coords = geocode(i)\n  primary_sc1[grep(i, primary_sc1$location_name), 3] = coords$lat\n  primary_sc1[grep(i, primary_sc1$location_name), 4] = coords$lon\n  \n}\n```\n:::\n\n\nWe should check if we still have missing coordinates. Note that we are missing information in the full_address column, however, it is not a great deal since we will be using the coordinates to create the sf objects later on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc1 %>%\n  filter(is.na(primary_sc1$lat) == TRUE)\n```\n:::\n\n\nWe are still missing coordinates for three schools. We will be filling these values manually.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_sc1[grep(\"St. Anthony’s Primary School\", primary_sc1$location_name), 3:4] = list(1.3796337949311097, 103.75033229288428)\n\nprimary_sc1[grep(\"St. Gabriel’s Primary School\", primary_sc1$location_name), 3:4] = list(1.3499742816603595, 103.86268328706147)\n\nprimary_sc1[grep(\"St. Stephen’s School\", primary_sc1$location_name), 3:4] = list(1.3189794629543288, 103.9179118196036)\n```\n:::\n\n\nWe are now good to go, we can proceed to creating a sf data frame, however, before doing so, I will export the data frame into my data folder to avoid using the Google Maps API again (it is free under a limited amount of queries).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(primary_sc1, \"data/aspatial/primary_schools.csv\", row.names = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_schools = read_csv(\"data/aspatial/primary_schools.csv\")\n```\n:::\n\n\n### Creating the sf data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprimary_schools.sf = st_as_sf(primary_schools,\n                         coords = c(\"lon\", \"lat\"),\n                         crs = 4326) %>%\n  st_transform(3414)\n```\n:::\n\n\n### Visualizing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(primary_schools.sf)+\n  tm_dots()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-68-1.png){width=672}\n:::\n:::\n\n\n### Creating a field with the Top 20 Primary Schools\n\nWe will now create an additional variable that indicates whether one primary school is considered good or not. I made the selection factor be whether the primary school is in the Top 20 primary schools or not. I extracted from the internet the Top 20 list that you may find below. With this list, we can create a dummy variable that stores a 1 (0) if the school is part (or not) of the Top 20.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop20_sc = c(\"Methodist Girls’ School (Primary)\", \"Catholic High School\", \"Tao Nan School\", \"Pei Hwa Presbyterian Primary School\", \"Holy Innocents’ Primary School\", \"Nan Hua Primary School\", \"CHIJ St. Nicholas Girls’ School\", \"Admiralty Primary School\", \"St. Hilda’s Primary School\", \"Ai Tong School\", \"Anglo-Chinese School (Junior)\", \"Chongfu School\", \"St. Joseph’s Institution Junior\", \"Anglo-Chinese School (Primary)\", \"Singapore Chinese Girls’ Primary School\", \"Nanyang Primary School\", \"South View Primary School\", \"Pei Chun Public School\", \"Kong Hwa School\", \"Rosyth School\")\n\nprimary_schools.sf[\"top20\"] = ifelse(primary_schools.sf$location_name %in% top20_sc == TRUE,\n                                     1, 0)\n```\n:::\n\n\nNote that I originally forgot to create this variable and am doing it after having ran all the regressions. Unfortunately, since my computer crashes most of the time when trying to perform the geographic regression, I won't be able to include it now, but I still made sure to include how to create this variable.\n\n## Shopping Mall data\n\nWe encounter the same problem with the shopping malls as when looking for a data set of primary schools, so I decided to scrape Wikipedia for this one.\n\nWe perform very similar steps as the previous section on primary schools, so I won't run you through every step.\n\n### Scraping Wikipedia to extract the list of malls in Singapore\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl = \"https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore\"\n\nres = GET(url)\n\nwiki_read <- xml2::read_html(res, encoding = \"UTF-8\")\n\ntestt = wiki_read %>%\n  html_nodes(\"div.div-col\") %>%\n  html_elements(\"ul\") %>%\n  html_elements(\"li\") %>%\n  html_text()\n\nmalls = str_replace(testt, \"\\\\[.*]\", \"\")\n```\n:::\n\n\n### Using the OneMap API to retrieve the malls' coordinates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls = data.frame()\n\nurl = \"https://developers.onemap.sg/commonapi/search\"\n\nfor (i in 1:length(malls)){\n  \n  query <- list(\"searchVal\" = malls[i],\n                \"returnGeom\" = \"Y\", \n                \"getAddrDetails\" = \"Y\")\n  result <- GET(url, query = query)\n  \n  if (length(content(result)$results) == 0){\n    new_row = c(malls[i], \n              NA,\n              NA,\n              NA)\n    shp_malls = rbind(shp_malls, new_row)\n    \n  } else{\n    new_row = c(malls[i], \n                content(result)$results[[1]]$ADDRESS,\n                content(result)$results[[1]]$LATITUDE,\n                content(result)$results[[1]]$LONGITUDE)\n    \n    shp_malls = rbind(shp_malls, new_row)\n    \n  }\n\n}\n\ncolnames(shp_malls) = c(\"location_name\", \"full_address\", \"lat\", \"lon\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(shp_malls$full_address))\n```\n:::\n\n\n### Filling missing information with ggmap\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls %>%\n  filter(is.na(shp_malls$full_address) == TRUE) %>%\n  select(1)\n```\n:::\n\n\nBefore using the Google Maps API, I decided to research about these nine malls and found that:\n\n-   The PoMo mall is now called GR.iD, so we shall change the name in the data frame\n\n-   The KINEX mall is found under the name KINEX, so we shall remove the additional information from the name\n\n-   The Paya Lebar Quarter mall is found under the name PLQ mall on Google Maps, so we shall change the name in the data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls[grep(\"PoMo\", shp_malls$location_name), 1] = \"GR.iD\";\n\nshp_malls[grep(\"KINEX\", shp_malls$location_name), 1] = \"KINEX\";\n\nshp_malls[grep(\"PLQ\", shp_malls$location_name), 1] = \"PLQ mall\"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nregister_google(key = \"xxx\")\n\nmissing_malls = shp_malls %>%\n  filter(is.na(shp_malls$full_address) == TRUE) %>%\n  `$`(location_name)\n\nfor (i in list(missing_malls)[[1]]){\n  coords = geocode(i)\n  shp_malls[grep(i, shp_malls$location_name), 3] = coords$lat\n  shp_malls[grep(i, shp_malls$location_name), 4] = coords$lon\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls %>%\n  filter(is.na(shp_malls$lat) == TRUE)\n```\n:::\n\n\n### Filling missing information manually\n\nWe are still missing coordinates of the KINEX mall. We will be filling these values manually.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls[grep(\"KINEX\", shp_malls$location_name), 3:4] = c(1.314893715213727, 103.89480904154526)\n```\n:::\n\n\nWe are now good to go, we can proceed to creating a sf data frame, however, before doing so, I will export the data frame into my data folder to avoid using the Google Maps API again (it is free under a limited amount of queries).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.csv(shp_malls, \"data/aspatial/shopping_malls.csv\", row.names = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls = read_csv(\"data/aspatial/shopping_malls.csv\")\n```\n:::\n\n\n### Creating an sf data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshp_malls.sf = st_as_sf(shp_malls,\n                        coords = c(\"lon\", \"lat\"),\n                        crs = 4326) %>%\n  st_transform(3414)\n```\n:::\n\n\n### Visualizing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(shp_malls.sf)+\n  tm_dots()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-81-1.png){width=672}\n:::\n:::\n\n\n# Preparing the final data frame\n\nIn this section, we will prepare the following variables:\n\nProximity to CBD ; Proximity to eldercare ; Proximity to foodcourt/hawker centres ; Proximity to MRT ; Proximity to park ; Proximity to good primary school ; Proximity to shopping mall ; Proximity to supermarket\n\nNumbers of kindergartens within 350m ; Numbers of childcare centres within 350m ; Numbers of bus stop within 350m ; Numbers of primary school within 1km\n\n## Proximity variables\n\n### Proximity to CBD\n\nWe will consider the Downtown Core planning area to be the Central Business District. Given the previous statement, we will compute the distance of each HDB flats to the CBD area.\n\nThe first step is to compute the nearest feature between the HDB flats and CDB area. With this, we then can create a column that stores the distance between the two features (e.g., distance between each flat and nearest part of the CBD).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbd_zone.sf = mpsz.sf %>%\n  filter(PLN_AREA_N == \"DOWNTOWN CORE\")\n\nnearest = st_nearest_feature(rp_3rooms.sf, cbd_zone.sf)\n\nrp_3rooms.sf$distance_to_cdb = as.numeric(\n  st_distance(rp_3rooms.sf, \n              cbd_zone.sf[nearest,],\n              by_element=TRUE) )\n```\n:::\n\n\nNote that I had forgot to compute this variable when running my regressions, so you won't see it later but I made sure to include the code to compute it.\n\n### Proximity to eldercare\n\n\n::: {.cell}\n\n```{.r .cell-code}\neldercare.sf = retrieved_variables.sf %>%\n  filter(variable_name == \"eldercare\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, eldercare.sf)\n\nrp_3rooms.sf$distance_to_eldercare = as.numeric(\n  st_distance(rp_3rooms.sf, \n              eldercare.sf[nearest,],\n              by_element=TRUE) )\n```\n:::\n\n\n### Proximity to food court / hawker centres\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhawker_centres.sf = retrieved_variables.sf %>%\n  filter(variable_name == \"hawker_centres\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, hawker_centres.sf)\n\nrp_3rooms.sf$distance_to_food = as.numeric(\n  st_distance(rp_3rooms.sf, \n              hawker_centres.sf[nearest,], \n              by_element=TRUE) )\n```\n:::\n\n\n### Proximity to MRT\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, mrt_exits.sf)\n\nrp_3rooms.sf$distance_to_mrt = as.numeric(\n  st_distance(rp_3rooms.sf, \n              mrt_exits.sf[nearest,],\n              by_element=TRUE) )\n```\n:::\n\n\n### Proximity to park\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparks.sf = retrieved_variables.sf %>%\n  filter(variable_name == \"parks\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, parks.sf)\n\nrp_3rooms.sf$distance_to_park = as.numeric(\n  st_distance(rp_3rooms.sf, \n              parks.sf[nearest,],\n              by_element=TRUE) )\n```\n:::\n\n\n### Proximity to good primary school\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, primary_schools.sf)\n\nrp_3rooms.sf$top20_schools = as.numeric(\n  st_distance(rp_3rooms.sf, \n              primary_schools.sf[nearest,],\n              by_element=TRUE) )\n```\n:::\n\n\n### Proximity to shopping mall\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, shp_malls.sf)\n\nrp_3rooms.sf$distance_to_mall = as.numeric(\n  st_distance(rp_3rooms.sf, \n              shp_malls.sf[nearest,], \n              by_element=TRUE) )\n```\n:::\n\n\n### Proximity to supermarket\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnearest = st_nearest_feature(rp_3rooms.sf, supermarkets.sf)\n\nrp_3rooms.sf$distance_to_supermarkets = as.numeric(\n  st_distance(rp_3rooms.sf, \n              supermarkets.sf[nearest,], \n              by_element=TRUE) )\n```\n:::\n\n\n## Number of ... within given distance\n\nThe first step is to create buffers for each HDB flat. We create two buffers, one of 350m and one of 1000m (1km).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbuffer_350  = st_buffer(rp_3rooms.sf, 350)\nbuffer_1000 = st_buffer(rp_3rooms.sf, 1000)\n```\n:::\n\n\nUsing these buffers will allow us to compute the number of a given variable inside the buffer.\n\n### Numbers of kindergartens within 350m\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkindergartens.sf = retrieved_variables.sf %>%\n  filter(variable_name == \"kindergartens\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf$nb_of_kindergartens = lengths(\n  st_intersects(buffer_350, kindergartens.sf))\n```\n:::\n\n\n### Numbers of childcare centres within 350m\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchild_care.sf = retrieved_variables.sf %>%\n  filter(variable_name == \"child_care\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf$nb_of_childcare = lengths(\n  st_intersects(buffer_350, child_care.sf))\n```\n:::\n\n\n### Numbers of bus stop within 350m\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf$nb_of_bus_stops = lengths(\n  st_intersects(buffer_350, bus_stops.sf))\n```\n:::\n\n\n### Numbers of primary school within 1km\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf$nb_of_primary_schools = lengths(\n  st_intersects(buffer_1000, primary_schools.sf))\n```\n:::\n\n\n## Saving the data\n\nWe will save the data into a rds file to avoid running all the previous code every time we would like to work on the assignment since some of these steps are very lengthy.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(rp_3rooms.sf, \"data/geospatial/final_dataset.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf = read_rds(\"data/geospatial/final_dataset.rds\")\n```\n:::\n\n\n## Check for missing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(rp_3rooms.sf))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nThere is no missing that so we can move on to creating the hedonistic pricing models.\n\n# Hedonic Pricing model\n\nThe first step to our hedonistic pricing model is to clean the name of our fields. We do so using the rename function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf = rp_3rooms.sf %>%\n  rename(\"01_to_03\" = \"01 TO 03\", \"04_to_06\" = \"04 TO 06\", \"07_to_09\" = \"07 TO 09\",\n         \"10_to_12\" = \"10 TO 12\", \"13_to_15\" = \"13 TO 15\", \"16_to_18\" = \"16 TO 18\",\n         \"19_to_21\" = \"19 TO 21\", \"22_to_24\" = \"22 TO 24\", \"25_to_27\" = \"25 TO 27\",\n         \"28_to_30\" = \"28 TO 30\", \"31_to_33\" = \"31 TO 33\", \"34_to_36\" = \"34 TO 36\",\n         \"37_to_39\" = \"37 TO 39\", \"40_to_42\" = \"40 TO 42\", \"43_to_45\" = \"43 TO 45\",\n         \"46_to_48\" = \"46 TO 48\", \"New_Generation\" = \"New Generation\", \n         \"Model_A\" = \"Model A\", \"Premium_Apartment\" = \"Premium Apartment\")\n```\n:::\n\n\n## Splitting the data\n\nNow that are fields are cleaned, we should split the data into two data frames. One data frame used for training and one for testing. We do so using the filter and grepl functions.\n\nNote that you can use regular expressions to be more efficient when trying to string match.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_analysis.sf = rp_3rooms.sf %>%\n  filter(grepl(\"202[12]\", month))\n\nrp_testing.sf = rp_3rooms.sf %>%\n  filter(grepl(\"2023\", month))\n```\n:::\n\n\n# Conventional OLS method\n\nThe first analysis we will perform is the \"standard\" or \"conventional\" OLS. This is a multiple linear regression that takes into account only our independent variables. It does not use geographical location as a determinant of the resale price of an HDB flat.\n\nBefore running the analysis, there are a few preliminary steps. We should check for: non-linear relationships between the independent variables and the dependent variables; multicollinearity; heteroscedasticity.\n\n## Multicollinearity\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrplot::corrplot(cor(rp_3rooms.sf %>% \n                         st_drop_geometry() %>%\n                         select(-c(1, 22, 23))), \n                   diag = FALSE, order = \"AOE\", tl.pos = \"td\", \n                   tl.cex = 0.5, method = \"number\", type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-105-1.png){width=672}\n:::\n:::\n\n\n## MLR model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(rp_3rooms.sf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_analysis.mlr <- lm(formula = resale_price ~ floor_area_sqm + remaining_lease +\n                      `01_to_03` + `04_to_06` + `07_to_09` + `10_to_12` + `13_to_15` + \n                      `16_to_18` + `19_to_21` + `22_to_24` + `25_to_27` + `28_to_30` + \n                      `31_to_33` + `34_to_36` + `37_to_39` + `40_to_42` + `43_to_45` + \n                      `New_Generation` + Improved + `Model_A` + Simplified + Standard + \n                      `Premium_Apartment` + DBSS + distance_to_eldercare + \n                      distance_to_food + distance_to_mrt + distance_to_park + \n                      distance_to_mall + distance_to_supermarkets + nb_of_kindergartens +\n                      nb_of_childcare + nb_of_bus_stops + nb_of_primary_schools, \n                    data = rp_analysis.sf)\n\nstargazer(rp_analysis.mlr, type=\"text\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n====================================================\n                             Dependent variable:    \n                         ---------------------------\n                                resale_price        \n----------------------------------------------------\nfloor_area_sqm                  3,946.537***        \n                                  (93.530)          \n                                                    \nremaining_lease                 2,754.191***        \n                                  (61.207)          \n                                                    \n`01_to_03`                     -257,839.693***      \n                                (52,620.249)        \n                                                    \n`04_to_06`                     -248,405.940***      \n                                (52,616.441)        \n                                                    \n`07_to_09`                     -241,109.221***      \n                                (52,616.860)        \n                                                    \n`10_to_12`                     -232,833.112***      \n                                (52,618.266)        \n                                                    \n`13_to_15`                     -224,504.937***      \n                                (52,626.152)        \n                                                    \n`16_to_18`                     -205,120.927***      \n                                (52,659.851)        \n                                                    \n`19_to_21`                     -174,800.777***      \n                                (52,757.140)        \n                                                    \n`22_to_24`                     -158,664.647***      \n                                (52,852.098)        \n                                                    \n`25_to_27`                     -127,272.290**       \n                                (52,922.790)        \n                                                    \n`28_to_30`                      -96,167.414*        \n                                (53,084.925)        \n                                                    \n`31_to_33`                       -79,389.789        \n                                (53,208.006)        \n                                                    \n`34_to_36`                       -58,544.715        \n                                (53,510.236)        \n                                                    \n`37_to_39`                       -47,678.241        \n                                (53,296.651)        \n                                                    \n`40_to_42`                       -28,303.576        \n                                (56,745.135)        \n                                                    \n`43_to_45`                       27,962.420         \n                                (58,710.939)        \n                                                    \nNew_Generation                 -429,929.634***      \n                                (10,800.164)        \n                                                    \nImproved                       -423,909.938***      \n                                (11,010.310)        \n                                                    \nModel_A                        -422,627.638***      \n                                (10,789.771)        \n                                                    \nSimplified                     -402,908.906***      \n                                (11,227.145)        \n                                                    \nStandard                       -413,750.267***      \n                                (11,376.659)        \n                                                    \nPremium_Apartment              -399,095.702***      \n                                (11,179.217)        \n                                                    \nDBSS                           -348,968.293***      \n                                (11,638.597)        \n                                                    \ndistance_to_eldercare            -16.072***         \n                                   (0.945)          \n                                                    \ndistance_to_food                 -19.181***         \n                                   (1.600)          \n                                                    \ndistance_to_mrt                  -27.268***         \n                                   (1.376)          \n                                                    \ndistance_to_park                 -20.903***         \n                                   (1.530)          \n                                                    \ndistance_to_mall                 -11.363***         \n                                   (1.352)          \n                                                    \ndistance_to_supermarkets          -5.749**          \n                                   (2.591)          \n                                                    \nnb_of_kindergartens             4,512.822***        \n                                  (642.853)         \n                                                    \nnb_of_childcare                 -2,789.315***       \n                                  (295.193)         \n                                                    \nnb_of_bus_stops                  -910.529***        \n                                  (188.399)         \n                                                    \nnb_of_primary_schools           -7,938.305***       \n                                  (369.917)         \n                                                    \nConstant                       675,321.297***       \n                                (54,923.892)        \n                                                    \n----------------------------------------------------\nObservations                       12,608           \nR2                                  0.638           \nAdjusted R2                         0.637           \nResidual Std. Error        52,512.632 (df = 12573)  \nF Statistic              652.049*** (df = 34; 12573)\n====================================================\nNote:                    *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n\n\n## Linearity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(residuals(rp_analysis.mlr), fitted.values(rp_analysis.mlr),\n     xlab=\"Residuals\", ylab=\"Fitted Values\")\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-108-1.png){width=672}\n:::\n:::\n\n\n## Heteroscedasticity\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngqtest(rp_analysis.mlr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tGoldfeld-Quandt test\n\ndata:  rp_analysis.mlr\nGQ = 0.9281659246132, df1 = 6269, df2 = 6269, p-value = 0.99841450489\nalternative hypothesis: variance increases from segment 1 to 2\n```\n:::\n:::\n\n\n# GWR methods\n\n## Converting sf data frame to SpatialPointDataFrame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_analysis.sp = as_Spatial(rp_analysis.sf)\n```\n:::\n\n\n### Computing adaptive bandwidth\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_analysis_adaptive <- bw.gwr(resale_price ~ floor_area_sqm + remaining_lease +\n                      X01_to_03 + X04_to_06 + X07_to_09 + X10_to_12 + X13_to_15 + \n                      X16_to_18 + X19_to_21 + X22_to_24 + X25_to_27 + X28_to_30 + \n                      X31_to_33 + X34_to_36 + X37_to_39 + X40_to_42 + X43_to_45 + \n                      New_Generation + Improved + Model_A + Simplified + Standard + \n                      Premium_Apartment + DBSS + distance_to_eldercare + \n                      distance_to_food + distance_to_mrt + distance_to_park + \n                      distance_to_mall + distance_to_supermarkets + nb_of_kindergartens +\n                      nb_of_childcare + nb_of_bus_stops + nb_of_primary_schools, \n                      data = rp_analysis.sp, approach=\"CV\", kernel=\"gaussian\",\n                      adaptive=TRUE, longlat=FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(bw_analysis_adaptive, \"data/model/bw_analysis_adaptive.rds\")\n```\n:::\n\n\n### Constructing the adaptive bandwidth gwr model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbw_adaptive <- read_rds(\"data/model/bw_analysis_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwr_adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm + remaining_lease + X01_to_03 +\n                            X04_to_06 + X07_to_09 + X10_to_12 + X13_to_15 + X16_to_18 + X19_to_21 +\n                            X22_to_24 + X25_to_27 + X28_to_30 + X31_to_33 + X34_to_36 + X37_to_39 + \n                            X40_to_42 + X43_to_45 + New_Generation + Improved + Model_A + Simplified + \n                            Standard + Premium_Apartment + DBSS + distance_to_eldercare + distance_to_food + \n                            distance_to_mrt + distance_to_park + distance_to_mall + distance_to_supermarkets + \n                            nb_of_kindergartens + nb_of_childcare + nb_of_bus_stops + nb_of_primary_schools, \n                          data = rp_analysis.sp, bw=bw_adaptive, kernel = 'gaussian', adaptive=TRUE, \n                          longlat = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwr_adaptive, \"data/model/gwr_analysis_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwr_adaptive = read_rds(\"data/model/gwr_analysis_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwr_adaptive\n```\n:::\n\n\n## Dropping geometry\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train <- st_coordinates(rp_analysis.sf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(coords_train, \"data/model/coords_train.rds\" )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train = read_rds(\"data/model/coords_train.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_analysis.no_geom = rp_analysis.sf %>% \n  st_drop_geometry() %>%\n  select(-c(1, 3, 22:23))\n```\n:::\n\n\n## Calibrating Random Forest Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_analysis.no_geom = rp_analysis.no_geom %>%\n  clean_names()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2410)\nrf <- ranger(resale_price ~ floor_area_sqm + remaining_lease +\n               x01_to_03 + x04_to_06 + x07_to_09 + x10_to_12 + x13_to_15 + \n               x16_to_18 + x19_to_21 + x22_to_24 + x25_to_27 + x28_to_30 + \n               x31_to_33 + x34_to_36 + x37_to_39 + x40_to_42 + x43_to_45 + \n               new_generation + improved + model_a + simplified + standard + \n               premium_apartment + dbss + distance_to_eldercare + \n               distance_to_food + distance_to_mrt + distance_to_park + \n               distance_to_mall + distance_to_supermarkets + nb_of_kindergartens +\n               nb_of_childcare + nb_of_bus_stops + nb_of_primary_schools, \n             data = rp_analysis.no_geom)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(rf)\n```\n:::\n\n\n## Calibrating Geographical Random Forest Model\n\n### Calibrating using training data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + remaining_lease +\n                       x01_to_03 + x04_to_06 + x07_to_09 + x10_to_12 + x13_to_15 + \n                       x16_to_18 + x19_to_21 + x22_to_24 + x25_to_27 + x28_to_30 + \n                       x31_to_33 + x34_to_36 + x37_to_39 + x40_to_42 + x43_to_45 + \n                       new_generation + improved + model_a + simplified + standard + \n                       premium_apartment + dbss + distance_to_eldercare + \n                       distance_to_food + distance_to_mrt + distance_to_park +\n                       distance_to_mall + distance_to_supermarkets + nb_of_kindergartens +\n                       nb_of_childcare + nb_of_bus_stops + nb_of_primary_schools,\n                     dframe=rp_analysis.no_geom, bw=bw_adaptive, kernel=\"adaptive\",\n                     coords=coords_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive250.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive <- read_rds(\"data/model/gwRF_adaptive.rds\")\n```\n:::\n\n\n# Testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(mpsz.sf)+\n  tm_polygons()+\ntm_shape(rp_3rooms.sf)+\n  tm_dots(col = \"blue\")+\ntm_shape(st_buffer(rp_3rooms.sf, 350))+\n  tm_fill(col = \"red\",\n          alpha = 0.1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrp_3rooms.sf %>%\n  filter(st_distance(rp_3rooms.sf, kindergartens.sf) <= 350)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nspatialrisk::concentration(rp_3rooms.sf, kindergartens.sf,\n                           value = count, radius = 350)\n```\n:::\n",
    "supporting": [
      "Take-home_Ex03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}